{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b813a7d1",
   "metadata": {},
   "source": [
    "# Indeed Webscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7fdf6c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9acb191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import logging\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314496eb",
   "metadata": {},
   "source": [
    "## Indeed Job Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc37b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadWindow_Time = 10\n",
    "attempts = 3\n",
    "\n",
    "\n",
    "def startChromeEngine():\n",
    "    Indeed_Url = \"https://de.indeed.com/?r=us\"\n",
    "    ser = Service(\"/Applications/chromedriver\")\n",
    "\n",
    "    # start chrome driver\n",
    "    driver = webdriver.Chrome(service=ser)\n",
    "    driver.get(Indeed_Url)\n",
    "\n",
    "    # wait for cookies window\n",
    "    time.sleep(loadWindow_Time)\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "def startSearchEngine(driver, job_title, location):\n",
    "    # accept cookies\n",
    "    driver.find_element(By.XPATH, \"//*[@id=\\\"onetrust-accept-btn-handler\\\"]\").click()\n",
    "\n",
    "    # enter job title\n",
    "    driver.find_element(By.XPATH, \"//*[@id=\\\"text-input-what\\\"]\").send_keys(job_title)\n",
    "\n",
    "    # enter location\n",
    "    driver.find_element(By.XPATH, \"//*[@id=\\\"text-input-where\\\"]\").send_keys(location)\n",
    "    # start search\n",
    "    driver.find_element(By.XPATH, \"//*[@id=\\\"text-input-where\\\"]\").send_keys(Keys.RETURN)\n",
    "\n",
    "    # wait for page to load \n",
    "    time.sleep(loadWindow_Time)\n",
    "    # sort result by publish data\n",
    "    driver.find_element(By.XPATH, \"//*[@id=\\\"resultsCol\\\"]/div[3]/div[4]/div[1]/span[2]/a\").click()\n",
    "    # wait for random pop up window\n",
    "    time.sleep(loadWindow_Time)\n",
    "    \n",
    "    # close random pop up window\n",
    "    driver.find_element(By.XPATH,\"//*[@id=\\\"popover-x\\\"]/button\").click()\n",
    "    \n",
    "    time.sleep(loadWindow_Time)\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "def startScrapingPage(driver, all_jobs_lst):\n",
    "    # get the job list container\n",
    "    for attempt in range(attempts):\n",
    "        try:\n",
    "            job_list_container = driver.find_element(By.XPATH, \"//*[@id=\\\"mosaic-provider-jobcards\\\"]\")\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # get all jobs in container\n",
    "    job_list = job_list_container.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "    # get all job ids in job_list\n",
    "    job_ids = []\n",
    "    try:\n",
    "        for job in job_list:\n",
    "            id = job.get_attribute(\"id\")\n",
    "            if id != \"\":\n",
    "                job_ids.append(id)\n",
    "    except:\n",
    "        time.sleep(loadWindow_Time)\n",
    "\n",
    "    # iterate over every job in job_ids\n",
    "    for job_id in job_ids:\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, f\"//*[@id=\\\"{job_id}\\\"]\").click()\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # switch to Job Description iframe\n",
    "        for attempt in range (attempts):\n",
    "            try:\n",
    "                iframe = driver.find_element(By.XPATH,\"//*[@id=\\\"vjs-container-iframe\\\"]\")\n",
    "                driver.switch_to.frame(iframe)\n",
    "                break\n",
    "            except:\n",
    "                time.sleep(loadWindow_Time)\n",
    "\n",
    "        for attempt in range(attempts):\n",
    "            # get job top card\n",
    "            try:\n",
    "                topCard = driver.find_element(By.XPATH, \"//*[@id=\\\"viewJobSSRRoot\\\"]/div/div[1]/div/div/div/div[1]/div/div[1]\")\n",
    "            except:\n",
    "                job_title = \"\"\n",
    "                company_name = \"\"\n",
    "                company_location = \"\"\n",
    "                job_type = \"\"\n",
    "                time.sleep(loadWindow_Time)\n",
    "                continue\n",
    "\n",
    "            # get job title\n",
    "            try:\n",
    "                job_title = topCard.find_element(By.CSS_SELECTOR,\".icl-u-xs-mb--xs.icl-u-xs-mt--none.jobsearch-JobInfoHeader-title.is-embedded\").text\n",
    "            except:\n",
    "                job_title = \"\"\n",
    "\n",
    "            # get company name\n",
    "            try:\n",
    "                company_name = driver.find_element(By.CSS_SELECTOR, \".icl-u-lg-mr--sm.icl-u-xs-mr--xs\").text\n",
    "            except:\n",
    "                company_name = \"\"\n",
    "\n",
    "            # get company location\n",
    "            try:\n",
    "                company_location = driver.find_element(By.CSS_SELECTOR,\"div[class='jobsearch-CompanyInfoWithoutHeaderImage'] div:nth-child(2)\").text\n",
    "            except:\n",
    "                company_location = \"\"\n",
    "            # get type of job\n",
    "            try:\n",
    "                job_type = driver.find_element(By.CSS_SELECTOR, \"body > div:nth-child(4) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(2) > span:nth-child(1)\").text\n",
    "            except:\n",
    "                job_type = \"\"\n",
    "\n",
    "\n",
    "        # get job description\n",
    "        for attempt in range(attempts):\n",
    "            try:\n",
    "                job_Description = driver.find_element(By.XPATH, \"//*[@id=\\\"jobDescriptionText\\\"]\").text\n",
    "                break\n",
    "            except:\n",
    "                job_Description = \"\"\n",
    "                time.sleep(loadWindow_Time)\n",
    "\n",
    "        # get current datetime\n",
    "        date_time = datetime.datetime.now().strftime(\"%d%b%Y-%H:%M:%S\")\n",
    "\n",
    "        # add all_jobs to all_jobs_lst\n",
    "        all_jobs = [job_id, job_title, company_name, company_location, job_type, job_Description, date_time]\n",
    "        all_jobs_lst.append(all_jobs)\n",
    "\n",
    "        # switch back to default frame to click on next job\n",
    "        driver.switch_to.default_content()\n",
    "\n",
    "    return all_jobs_lst\n",
    "\n",
    "\n",
    "def getNextPage(driver):\n",
    "    # click on next Page button\n",
    "    driver.find_element(By.XPATH, \"//*[@id=\\\"resultsCol\\\"]/nav/div/ul/li[6]/a\").click()\n",
    "    time.sleep(loadWindow_Time)\n",
    "\n",
    "    return driver\n",
    "\n",
    "\n",
    "def saveAsCSV(all_jobs_lst, page_nr):\n",
    "    df = pd.DataFrame(all_jobs_lst)\n",
    "    df.to_csv(\"/Users/jan/Documents/7.Semester/Datenanalyse in der Praxis/SeminarArbeit/Data/Indeed_Jobs\"+str(page_nr)+\".csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02b442",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "ammount_Of_Pages=35\n",
    "driver = startChromeEngine()\n",
    "\n",
    "driver = startSearchEngine(driver, \"Data Analyst\", \"Deutschland\")\n",
    "\n",
    "for page_Number in range(ammount_Of_Pages):\n",
    "    newPage_Number=page_Number+11\n",
    "    all_jobs_lst=[]\n",
    "    all_jobs_lst = startScrapingPage(driver,all_jobs_lst)\n",
    "    saveAsCSV(all_jobs_lst, newPage_Number)\n",
    "    driver = getNextPage(driver)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d5bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
